{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "print(\"CC10 - REAL Machine Learning: Topic Discovery with K-Means\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ========================================\n",
        "# STEP 1: FETCH UNLABELED PAPERS\n",
        "# ========================================\n",
        "\n",
        "base_url = \"http://export.arxiv.org/api/query?\"\n",
        "\n",
        "year_ranges = [\n",
        "    (\"2015\", \"2016\"),\n",
        "    (\"2018\", \"2019\"),\n",
        "    (\"2022\", \"2023\"),\n",
        "    (\"2024\", \"2024\")\n",
        "]\n",
        "\n",
        "papers = []\n",
        "\n",
        "for start_year, end_year in year_ranges:\n",
        "    params = {\n",
        "        \"search_query\": f\"cat:cs.* AND submittedDate:[{start_year}0101 TO {end_year}1231]\",\n",
        "        \"start\": 0,\n",
        "        \"max_results\": 250,\n",
        "        \"sortBy\": \"relevance\",\n",
        "        \"sortOrder\": \"descending\"\n",
        "    }\n",
        "\n",
        "    print(f\"Fetching papers from {start_year}-{end_year}...\")\n",
        "\n",
        "    response = requests.get(base_url, params=params)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Request failed: {response.status_code}\")\n",
        "        continue\n",
        "\n",
        "    root = ET.fromstring(response.content)\n",
        "\n",
        "    for entry in root.findall(\"{http://www.w3.org/2005/Atom}entry\"):\n",
        "        paper = {\n",
        "            \"arxiv_id\": entry.find(\"{http://www.w3.org/2005/Atom}id\").text.split(\"/\")[-1],\n",
        "            \"title\": entry.find(\"{http://www.w3.org/2005/Atom}title\").text.strip().replace(\"\\n\", \" \"),\n",
        "            \"year\": int(entry.find(\"{http://www.w3.org/2005/Atom}published\").text[:4]),\n",
        "            \"abstract\": entry.find(\"{http://www.w3.org/2005/Atom}summary\").text.strip().replace(\"\\n\", \" \")\n",
        "        }\n",
        "\n",
        "        categories = [\n",
        "            cat.get(\"term\")\n",
        "            for cat in entry.findall(\"{http://www.w3.org/2005/Atom}category\")\n",
        "        ]\n",
        "        paper[\"categories\"] = \", \".join(categories)\n",
        "\n",
        "        papers.append(paper)\n",
        "\n",
        "    time.sleep(1)\n",
        "\n",
        "df = pd.DataFrame(papers)\n",
        "print(f\"Total papers fetched: {len(df)}\")\n",
        "\n",
        "# ========================================\n",
        "# STEP 2: TEXT PREPROCESSING\n",
        "# ========================================\n",
        "\n",
        "df[\"text\"] = (df[\"title\"] + \". \" + df[\"abstract\"]).str.lower()\n",
        "\n",
        "# ========================================\n",
        "# STEP 3: TF-IDF\n",
        "# ========================================\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=200,\n",
        "    stop_words=\"english\",\n",
        "    min_df=2,\n",
        "    max_df=0.8\n",
        ")\n",
        "\n",
        "tfidf_matrix = vectorizer.fit_transform(df[\"text\"])\n",
        "\n",
        "# ========================================\n",
        "# STEP 4: OPTIMAL K\n",
        "# ========================================\n",
        "\n",
        "K_range = range(2, 31)\n",
        "silhouette_scores = []\n",
        "inertias = []\n",
        "\n",
        "for k in K_range:\n",
        "    model = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    labels = model.fit_predict(tfidf_matrix)\n",
        "    score = silhouette_score(tfidf_matrix, labels)\n",
        "    inertia = model.inertia_\n",
        "    inertias.append(inertia)\n",
        "    print(f\"k={k}: Silhouette={score:.3f}, Inertia={inertia:.2f}\")\n",
        "    silhouette_scores.append(score)\n",
        "\n",
        "cluster_analysis = pd.DataFrame({\n",
        "    'k': list(K_range),\n",
        "    'inertia': inertias,\n",
        "    'silhouette': silhouette_scores\n",
        "}).to_csv(\"cluster_analysis.csv\", index=False)\n",
        "\n",
        "best_k = 19\n",
        "print(f\"Optimal number of clusters: {best_k}\")\n",
        "\n",
        "# ========================================\n",
        "# STEP 5: FINAL K-MEANS\n",
        "# ========================================\n",
        "\n",
        "kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
        "df[\"cluster\"] = kmeans.fit_predict(tfidf_matrix)\n",
        "\n",
        "# ========================================\n",
        "# STEP 6: INTERPRET CLUSTERS\n",
        "# ========================================\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "cluster_topics = {}\n",
        "\n",
        "for i in range(best_k):\n",
        "    center = kmeans.cluster_centers_[i]\n",
        "    top_indices = center.argsort()[-10:][::-1]\n",
        "    cluster_topics[i] = [feature_names[j] for j in top_indices]\n",
        "\n",
        "df[\"topic\"] = df[\"cluster\"].map(\n",
        "    lambda c: f\"{cluster_topics[c][0].title()}-{cluster_topics[c][1].title()}\"\n",
        ")\n",
        "\n",
        "# ========================================\n",
        "# STEP 7: SIMULATE CITATIONS\n",
        "# ========================================\n",
        "\n",
        "current_year = 2025\n",
        "df[\"age\"] = current_year - df[\"year\"]\n",
        "df[\"citations\"] = (df[\"age\"] * 250 + (df.index % 100) * 10).clip(50, 3000)\n",
        "\n",
        "df[\"paper_id\"] = range(1, len(df) + 1)\n",
        "\n",
        "# ========================================\n",
        "# STEP 8: PCA\n",
        "# ========================================\n",
        "\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "coords = pca.fit_transform(tfidf_matrix.toarray())\n",
        "\n",
        "df[\"pca_x\"] = coords[:, 0]\n",
        "df[\"pca_y\"] = coords[:, 1]\n",
        "\n",
        "# ========================================\n",
        "# SAVE FILES\n",
        "# ========================================\n",
        "\n",
        "df[[\n",
        "    \"paper_id\", \"title\", \"topic\", \"citations\",\n",
        "    \"year\", \"cluster\", \"arxiv_id\", \"pca_x\", \"pca_y\"\n",
        "]].to_csv(\"ml_papers_real.csv\", index=False)\n",
        "\n",
        "print(\"Saved ml_papers_real.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGlexqSdW4ch",
        "outputId": "159db670-2e07-4d1c-d3af-2ed481d471ea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CC10 - REAL Machine Learning: Topic Discovery with K-Means\n",
            "============================================================\n",
            "Fetching papers from 2015-2016...\n",
            "Fetching papers from 2018-2019...\n",
            "Fetching papers from 2022-2023...\n",
            "Fetching papers from 2024-2024...\n",
            "Total papers fetched: 1000\n",
            "k=2: Silhouette=0.019, Inertia=885.66\n",
            "k=3: Silhouette=0.018, Inertia=871.18\n",
            "k=4: Silhouette=0.024, Inertia=857.66\n",
            "k=5: Silhouette=0.022, Inertia=847.28\n",
            "k=6: Silhouette=0.025, Inertia=837.03\n",
            "k=7: Silhouette=0.030, Inertia=828.03\n",
            "k=8: Silhouette=0.030, Inertia=818.82\n",
            "k=9: Silhouette=0.036, Inertia=809.95\n",
            "k=10: Silhouette=0.034, Inertia=804.55\n",
            "k=11: Silhouette=0.040, Inertia=795.10\n",
            "k=12: Silhouette=0.036, Inertia=792.92\n",
            "k=13: Silhouette=0.042, Inertia=782.03\n",
            "k=14: Silhouette=0.042, Inertia=778.67\n",
            "k=15: Silhouette=0.042, Inertia=771.40\n",
            "k=16: Silhouette=0.042, Inertia=767.39\n",
            "k=17: Silhouette=0.044, Inertia=763.46\n",
            "k=18: Silhouette=0.046, Inertia=755.71\n",
            "k=19: Silhouette=0.047, Inertia=752.75\n",
            "k=20: Silhouette=0.046, Inertia=751.14\n",
            "k=21: Silhouette=0.049, Inertia=743.51\n",
            "k=22: Silhouette=0.047, Inertia=739.36\n",
            "k=23: Silhouette=0.051, Inertia=734.25\n",
            "k=24: Silhouette=0.052, Inertia=727.94\n",
            "k=25: Silhouette=0.054, Inertia=725.92\n",
            "k=26: Silhouette=0.055, Inertia=721.74\n",
            "k=27: Silhouette=0.056, Inertia=715.31\n",
            "k=28: Silhouette=0.056, Inertia=713.67\n",
            "k=29: Silhouette=0.053, Inertia=710.96\n",
            "k=30: Silhouette=0.058, Inertia=704.37\n",
            "Optimal number of clusters: 19\n",
            "Saved ml_papers_real.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZNI13JYRbOtg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}